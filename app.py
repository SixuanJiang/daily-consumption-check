# app.py
import streamlit as st
import pandas as pd
import numpy as np
import re
import unicodedata
from io import BytesIO
from urllib.parse import quote
from collections import defaultdict

# ============ é¡µé¢ä¸Žå¸¸é‡ ============
st.set_page_config(page_title="Daily Consumption Check", page_icon="ðŸ“Š", layout="wide")
st.title("ðŸ“Š Daily Consumption Check (Google Sheets + One-click Check)")

SHEETS = {
    "raw_unit":       ("raw unit calculation", ["Name", "Unit calculation", "Type"]),
    "raw_to_semi":    ("raw to semi",         ["Semi/100g", "Made From", "Quantity", "Unit"]),
    "semi_to_semi":   ("semi to semi",        ["Semi/Unit", "Made From", "Quantity", "Unit"]),
    "semi_to_prod":   ("Semi to Product",     ["Product/Bowl", "Made From", "Quantity", "Unit"]),
    "raw_to_prod":    ("Raw to Product",      ["Product", "Made From", "Quantity", "Unit"]),
    "am_raw":         ("AM_Opening_Raw",      ["Ingredient", "Quantity", "Unit"]),
    "am_semi":        ("AM_Opening_semi",     ["Semi", "Quantity", "Unit"]),
    "purch_raw":      ("Purchases_Raw",       ["Ingredient", "Quantity", "Unit"]),
    "pm_raw":         ("PM_Ending_Raw",       ["Ingredient", "Quantity", "Unit"]),
    "pm_semi":        ("PM_Ending_semi",      ["Semi", "Quantity", "Unit"]),
    "prod_qty":       ("Dish_Production",     ["Product", "Quantity"]),
}

UNIT_SYNONYMS = {
    "pcs":"piece","pc":"piece","pieces":"piece",
    "bag":"bag","bags":"bag","box":"box","boxes":"box",
    "btl":"bottle","bottle":"bottle","bottles":"bottle",
    "can":"can","cans":"can",
}
BASE_UNIT_SYNONYMS = {"pieces":"piece","pcs":"piece","pc":"piece"}
RE_UNITCALC = re.compile(r'^\s*(\d+(?:\.\d+)?)\s*(g|ml|piece)s?\s*/\s*([a-zA-Z]+)\s*$', re.IGNORECASE)

# ============ å°å·¥å…· ============
def _norm(s):
    if pd.isna(s): return ""
    return str(s).strip()

def _num(x):
    try:
        if pd.isna(x) or str(x).strip()=="":
            return 0.0
        return float(str(x).strip())
    except:
        return 0.0

def _clean_header(name: str) -> str:
    if name is None:
        return ""
    s = unicodedata.normalize("NFKC", str(name))
    s = " ".join(s.strip().split())
    return s

def normalize_and_validate(df: pd.DataFrame, required_cols: list, sheet_label: str) -> pd.DataFrame:
    df = df.copy()
    df.columns = [_clean_header(c) for c in df.columns]

    alias_map = {
        "ingredient": "Ingredient", "ingredients": "Ingredient",
        "qty": "Quantity", "amount": "Quantity",
        "product/bowl": "Product/Bowl",
        "semi/100 g": "Semi/100g", "semi/unit": "Semi/Unit",
        "product ": "Product", " semi": "Semi",
    }
    new_cols = []
    for c in df.columns:
        key = c.lower()
        mapped = alias_map.get(key)
        new_cols.append(mapped if mapped else c)
    df.columns = [_clean_header(c) for c in new_cols]

    missing = [col for col in required_cols if col not in df.columns]
    if missing:
        st.error(
            f"ã€{sheet_label}ã€‘ç¼ºå°‘å¿…éœ€åˆ—ï¼š{missing}ã€‚å½“å‰åˆ—ï¼š{list(df.columns)}\n"
            f"è¯·ç¡®ä¿ç¬¬ä¸€è¡Œè¡¨å¤´å®Œå…¨ä¸ºï¼š{required_cols}ï¼ˆå¤§å°å†™ä¸Žç©ºæ ¼ä¸€è‡´ï¼‰ã€‚"
        )
        for m in missing:
            df[m] = None
    # è°ƒæ•´é¡ºåºï¼Œå¿…éœ€åˆ—åœ¨å‰
    ordered = [*required_cols, *[c for c in df.columns if c not in required_cols]]
    df = df[ordered]
    return df

def norm_unit(u: str) -> str:
    u = _norm(u).lower()
    u = UNIT_SYNONYMS.get(u, u)
    u = BASE_UNIT_SYNONYMS.get(u, u)
    return u

# ============ ä¸šåŠ¡å‡½æ•° ============
def build_pack_map(dfs):
    pack_map = {}
    df = dfs["raw_unit"]
    for _, r in df.iterrows():
        name = _norm(r.get("Name"))
        rule = _norm(r.get("Unit calculation"))
        if not name or not rule:
            continue
        m = RE_UNITCALC.match(rule)
        if not m:
            continue
        qty, base_u, pack_u = m.groups()
        base_u = norm_unit(base_u)
        pack_u = norm_unit(pack_u)
        pack_map[name.lower()] = {
            "base_qty": float(qty),
            "base_unit": base_u,
            "pack_unit": pack_u
        }
    return pack_map

def convert_to_base(name, qty, unit, pack_map):
    if qty == 0: return 0.0
    u = norm_unit(unit)
    nm_key = _norm(name).lower()
    if u in ["g","ml","piece"]:
        return qty
    rule = pack_map.get(nm_key)
    if rule and u == rule["pack_unit"]:
        return qty * rule["base_qty"]
    return qty

def build_bom_maps(dfs):
    semi_raw  = defaultdict(lambda: defaultdict(float))
    semi_semi = defaultdict(lambda: defaultdict(float))
    prod_semi = defaultdict(lambda: defaultdict(float))
    prod_raw  = defaultdict(lambda: defaultdict(float))
    for _, r in dfs["raw_to_semi"].iterrows():
        semi_raw[_norm(r["Semi/100g"])][_norm(r["Made From"])] += _num(r["Quantity"])
    for _, r in dfs["semi_to_semi"].iterrows():
        semi_semi[_norm(r["Semi/Unit"])][_norm(r["Made From"])] += _num(r["Quantity"])
    for _, r in dfs["semi_to_prod"].iterrows():
        prod_semi[_norm(r["Product/Bowl"])][_norm(r["Made From"])] += _num(r["Quantity"])
    for _, r in dfs["raw_to_prod"].iterrows():
        prod_raw[_norm(r["Product"])][_norm(r["Made From"])] += _num(r["Quantity"])
    return semi_raw, semi_semi, prod_semi, prod_raw

def read_production(dfs):
    prod_qty = defaultdict(float)
    for _, r in dfs["prod_qty"].iterrows():
        prod_qty[_norm(r["Product"])] += _num(r["Quantity"])
    return prod_qty

def expand_semi_demand(prod_qty, prod_semi, semi_semi):
    total = defaultdict(float)
    for prod, qty in prod_qty.items():
        for semi, per_unit in prod_semi.get(prod, {}).items():
            total[semi] += qty * per_unit
    queue = list(total.items())
    while queue:
        semi, need = queue.pop()
        for child, per_unit in semi_semi.get(semi, {}).items():
            add = need * per_unit
            total[child] += add
            queue.append((child, add))
    return total

def calc_theoretical_raw_need(prod_qty, prod_raw, total_semi_need, semi_raw):
    raw_need = defaultdict(float)
    for prod, qty in prod_qty.items():
        for raw, per_unit in prod_raw.get(prod, {}).items():
            raw_need[raw] += qty * per_unit
    for semi, sneed in total_semi_need.items():
        for raw, per_unit in semi_raw.get(semi, {}).items():
            raw_need[raw] += sneed * per_unit
    return raw_need

def compare_and_report(theoretical_map, actual_map, label, pct_tol):
    items = []
    for name in sorted(set(theoretical_map) | set(actual_map)):
        theo = theoretical_map.get(name, 0.0)
        act  = actual_map.get(name, 0.0)
        diff = act - theo
        if abs(theo) < 1e-9:
            pct = 0.0 if abs(act) < 1e-9 else (1.0 if diff > 0 else -1.0)
        else:
            pct = diff / theo
        if pct > pct_tol:       color = "red"
        elif pct < -pct_tol:    color = "green"
        else:                   color = "black"
        if color != "black":
            items.append((abs(diff), name, theo, act, diff, pct, color))

    if not items:
        return f"<h3>{label} Pass âœ…</h3>", pd.DataFrame()

    items.sort(reverse=True)
    rows = [
        f"<tr><td>{name}</td><td>{theo:.2f}</td><td>{act:.2f}</td>"
        f"<td style='color:{color}'>{diff:.2f} ({pct:+.0%})</td></tr>"
        for _, name, theo, act, diff, pct, color in items
    ]
    df_out = pd.DataFrame(
        [{"Name": name, "Theoretical": theo, "Actual": act, "Diff": diff, "Diff%": pct, "Type": label}
         for _, name, theo, act, diff, pct, color in items]
    )
    html = (
        f"<h3>{label} Issues</h3>"
        f"<table border=1><tr><th>Name</th><th>Theoretical</th><th>Actual</th><th>Diff</th></tr>"
        f"{''.join(rows)}</table>"
    )
    return html, df_out

# ============ Google Sheets è¯»å– ============
def gs_export_csv_url(sheet_id: str, tab_name: str) -> str:
    # æ³¨æ„ sheet å‚æ•°è¦ URL ç¼–ç ï¼ˆtab åå¤§å°å†™ä¸Žç©ºæ ¼å¿…é¡»ä¸Žåº•éƒ¨æ ‡ç­¾å®Œå…¨ä¸€è‡´ï¼‰
    return f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv&sheet={quote(tab_name)}"

@st.cache_data(show_spinner=False, ttl=60)
def load_from_gs(sheet_id: str):
    dfs = {}
    errors = []
    for key, (tab, cols) in SHEETS.items():
        url = gs_export_csv_url(sheet_id, tab)
        try:
            df = pd.read_csv(url, dtype=str).fillna("")
            # å°è¯•æŠŠæ•°é‡åˆ—è½¬ä¸ºæ•°å­—ï¼Œå…¶ä»–ä¿æŒå­—ç¬¦ä¸²
            for c in df.columns:
                if c.lower() in ("quantity",):
                    df[c] = pd.to_numeric(df[c], errors="coerce")
            df = normalize_and_validate(df, cols, tab)
            dfs[key] = df
        except Exception as e:
            errors.append(f"è¯»å– {tab} å¤±è´¥ï¼š{e}")
            dfs[key] = pd.DataFrame(columns=cols)
    return dfs, errors

# ============ ä¸Šä¼  Excel è¯»å– ============
def load_from_xlsx(file):
    xls = pd.ExcelFile(file)
    dfs = {}
    errors = []
    for key, (tab, cols) in SHEETS.items():
        try:
            if tab in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=tab).dropna(how="all")
                df = normalize_and_validate(df, cols, tab)
                dfs[key] = df
            else:
                errors.append(f"ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘å·¥ä½œè¡¨ï¼š{tab}")
                dfs[key] = pd.DataFrame(columns=cols)
        except Exception as e:
            errors.append(f"è¯»å– {tab} å¤±è´¥ï¼š{e}")
            dfs[key] = pd.DataFrame(columns=cols)
    return dfs, errors

def export_workbook(dfs):
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as w:
        for key, (sheet, cols) in SHEETS.items():
            df = dfs[key].copy()
            for c in cols:
                if c not in df.columns:
                    df[c] = None
            df = df[cols]
            df.to_excel(w, sheet_name=sheet, index=False)
    output.seek(0)
    return output

# ============ ç•Œé¢ï¼šæ•°æ®æº ============

with st.sidebar:
    st.header("ðŸ“ æ•°æ®æº")
    src = st.radio("é€‰æ‹©æ•°æ®æº", ["Google Sheets", "ä¸Šä¼  Excel"], horizontal=True)

    if src == "Google Sheets":
        sheet_id = st.text_input(
            "Google Sheet ID",
            placeholder="ä¾‹å¦‚ï¼š11Ln80T1iUp8kAPoNhdBjS1Xi5dsxSSANhGoYPa08GoA",
        )
        if sheet_id:
            st.link_button("æ‰“å¼€è¯¥è¡¨", f"https://docs.google.com/spreadsheets/d/{sheet_id}/edit", help="æ–°çª—å£é¢„è§ˆ")
    else:
        up = st.file_uploader("ä¸Šä¼ å·¥ä½œç°¿ï¼ˆ.xlsxï¼‰", type=["xlsx"])

    st.divider()
    pct = st.slider("å®¹å·®ï¼ˆÂ±%ï¼‰", 5, 50, 15, step=1) / 100
    run = st.button("ðŸš€ è¿è¡Œæ ¡éªŒ", use_container_width=True)

# é¢„è§ˆ Google Sheetsï¼ˆå¯åä½œç¼–è¾‘ï¼‰
if src == "Google Sheets":
    col_iframe, col_app = st.columns([0.45, 0.55])
    with col_iframe:
        st.subheader("åœ¨çº¿è¡¨ï¼ˆå¯åä½œç¼–è¾‘ï¼‰")
        if 'sheet_id' in locals() and sheet_id:
            st.components.v1.iframe(
                f"https://docs.google.com/spreadsheets/d/{sheet_id}/edit?usp=sharing",
                height=520
            )
        else:
            st.info("åœ¨å·¦ä¾§è¾“å…¥ Google Sheet ID åŽå¯é¢„è§ˆã€‚")
else:
    col_app = st.container()

with col_app:
    st.subheader("æ ¡éªŒç»“æžœ")
    if run:
        with st.spinner("æ­£åœ¨æŠ“å–å¹¶æ ¡éªŒâ€¦"):
            if src == "Google Sheets":
                if not sheet_id:
                    st.error("è¯·åœ¨å·¦ä¾§è¾“å…¥ Google Sheet IDã€‚")
                    st.stop()
                dfs, errs = load_from_gs(sheet_id)
            else:
                if not up:
                    st.error("è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶ã€‚")
                    st.stop()
                dfs, errs = load_from_xlsx(up)

            for msg in errs:
                st.warning(msg)

            # â€”â€”â€” è®¡ç®— â€”â€”â€”
            pack_map = build_pack_map(dfs)
            semi_raw, semi_semi, prod_semi, prod_raw = build_bom_maps(dfs)
            prod_qty = read_production(dfs)
            total_semi_need = expand_semi_demand(prod_qty, prod_semi, semi_semi)
            theo_raw  = calc_theoretical_raw_need(prod_qty, prod_raw, total_semi_need, semi_raw)
            theo_semi = total_semi_need

            # å®žé™…
            am_raw = defaultdict(float); purch = defaultdict(float); pm_raw = defaultdict(float)
            for _, r in dfs["am_raw"].iterrows():
                am_raw[_norm(r["Ingredient"])] += convert_to_base(r["Ingredient"], _num(r["Quantity"]), r.get("Unit",""), pack_map)
            for _, r in dfs["purch_raw"].iterrows():
                purch[_norm(r["Ingredient"])]   += convert_to_base(r["Ingredient"], _num(r["Quantity"]), r.get("Unit",""), pack_map)
            for _, r in dfs["pm_raw"].iterrows():
                pm_raw[_norm(r["Ingredient"])]  += convert_to_base(r["Ingredient"], _num(r["Quantity"]), r.get("Unit",""), pack_map)
            actual_raw = defaultdict(float)
            for name in set(am_raw) | set(purch) | set(pm_raw):
                actual_raw[name] = am_raw.get(name,0.0) + purch.get(name,0.0) - pm_raw.get(name,0.0)

            am_semi = defaultdict(float); pm_semi = defaultdict(float)
            for _, r in dfs["am_semi"].iterrows():
                am_semi[_norm(r["Semi"])] += _num(r["Quantity"])
            for _, r in dfs["pm_semi"].iterrows():
                pm_semi[_norm(r["Semi"])] += _num(r["Quantity"])
            actual_semi = defaultdict(float)
            for name in set(am_semi) | set(pm_semi):
                actual_semi[name] = am_semi.get(name,0.0) - pm_semi.get(name,0.0)

            # æŠ¥å‘Š
            raw_html,  raw_df  = compare_and_report(theo_raw,  actual_raw,  "RAW",  pct)
            semi_html, semi_df = compare_and_report(theo_semi, actual_semi, "SEMI", pct)

        st.markdown(raw_html,  unsafe_allow_html=True)
        st.markdown(semi_html, unsafe_allow_html=True)

        if not raw_df.empty or not semi_df.empty:
            out = pd.concat([raw_df, semi_df], ignore_index=True)
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½ Issues (CSV)",
                out.to_csv(index=False).encode("utf-8"),
                file_name="issues.csv",
                mime="text/csv"
            )

# ============ å¤‡ç”¨ï¼šå¯¼å‡ºå½“å‰æ•°æ®åˆ° Excelï¼ˆä»…å½“æ˜¯ä¸Šä¼ /å·²è¯»å…¥æ—¶å¯ç”¨ï¼‰ ============
with st.expander("â¬‡ï¸ å¯¼å‡ºå½“å‰å·¥ä½œç°¿ï¼ˆ.xlsxï¼‰"):
    st.write("å½“ä½ æ˜¯ä»Ž Google Sheets æ‹‰å–æ—¶ï¼Œè¿™é‡Œå¯¼å‡ºçš„ä»…æ˜¯å½“å‰æ‹‰å–åˆ°çš„å¿«ç…§ã€‚")
    if src == "Google Sheets":
        if 'sheet_id' in locals() and sheet_id and st.button("å¯¼å‡ºï¼ˆGoogle Sheets å¿«ç…§ï¼‰"):
            dfs, _ = load_from_gs(sheet_id)
            buf = export_workbook(dfs)
            st.download_button("ç‚¹å‡»ä¸‹è½½", data=buf, file_name="inventory.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        if 'up' in locals() and up:
            dfs, _ = load_from_xlsx(up)
            buf = export_workbook(dfs)
            st.download_button("ç‚¹å‡»ä¸‹è½½", data=buf, file_name="inventory.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ============ å¡«è¡¨è§„èŒƒ ============
with st.expander("ðŸ“˜ å¡«è¡¨è§„èŒƒï¼ˆç‚¹å¼€æŸ¥çœ‹ï¼‰"):
    st.markdown("""
- **å¿…é¡»çš„å·¥ä½œè¡¨ä¸Žåˆ—åï¼ˆä¸¥æ ¼åŒ¹é…ï¼‰**  
  - raw unit calculation: `Name`, `Unit calculation` (å¦‚ `100g/can`), `Type`  
  - raw to semi: `Semi/100g`, `Made From`, `Quantity`, `Unit`  
  - semi to semi: `Semi/Unit`, `Made From`, `Quantity`, `Unit`  
  - Semi to Product: `Product/Bowl`, `Made From`, `Quantity`, `Unit`  
  - Raw to Product: `Product`, `Made From`, `Quantity`, `Unit`  
  - AM_Opening_Raw / Purchases_Raw / PM_Ending_Raw: `Ingredient`, `Quantity`, `Unit`  
  - AM_Opening_semi / PM_Ending_semi: `Semi`, `Quantity`, `Unit`  
  - Dish_Production: `Product`, `Quantity`

- **é¢œè‰²è§„åˆ™**ï¼šçº¢=ç”¨å¤šï¼ˆ> +å®¹å·®ï¼‰ï¼Œç»¿=ç”¨å°‘ï¼ˆ< âˆ’å®¹å·®ï¼‰ï¼›å½“ **Theoretical=0** ä¸”æœ‰æ¶ˆè€—æ—¶ï¼ŒæŒ‰ **Â±100%** æ˜¾ç¤ºã€‚  
- **å•ä½**ï¼š`g / ml / piece` æˆ–åŒ…å•ä½ï¼ˆbag/box/can/bottleâ€¦ï¼‰ï¼›åŒ…å•ä½æ¢ç®—åœ¨ **raw unit calculation** çš„ `Unit calculation` é‡Œé…ç½®ï¼ˆå¦‚ `100g/can`ï¼‰ã€‚  
- **åˆ—åæ¸…æ´—**ï¼šè‡ªåŠ¨åŽ»ä¸å¯è§å­—ç¬¦/å¤šä½™ç©ºæ ¼ï¼Œå¸¸è§åˆ«åä¼šè¢«è‡ªåŠ¨æ˜ å°„ï¼ˆå¦‚ `qty`â†’`Quantity`ï¼‰ï¼Œç¼ºåˆ—ä¼šåœ¨é¡µé¢ç›´æŽ¥æç¤ºã€‚
""")

